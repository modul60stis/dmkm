{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OneR\n",
    "> OneR, kependekan dari \"One Rule\", adalah algoritma klasifikasi yang sederhana, namun akurat, yang menghasilkan satu aturan untuk setiap prediktor dalam data, kemudian memilih aturan dengan total error terkecil sebagai \"One Rule\". Untuk membuat aturan prediktor, perlu membuat tabel frekuensi untuk setiap prediktor terhadap target. Kemudian hitung total error untuk setiap predictor dan pilihlah prediktor dengan total error terkecil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import library required\n",
    "Library yang digunakan adalah **pandas, numpy, operator, dan sklearn**. Silahkan install terlebih dahulu jika belum menginstallnya dengan perintah `pip install nama-library`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "Data yang digunakan adalah data bawaan sklearn library. Jika ingin menggunakan data sendiri silahkan pakai perintah `pd.read_csv()` atau `pd.read_excel()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "..      ...  \n",
       "145       2  \n",
       "146       2  \n",
       "147       2  \n",
       "148       2  \n",
       "149       2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_iris(as_frame = True)\n",
    "X = dataset.data\n",
    "y= dataset.target\n",
    "dataset.frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catagorized Data\n",
    "Jika data masih ada variabel yang berbentuk continue, perlu di konversi ke bentuk diskrit terlebih dahulu. Data iris ini semua varibel X-nya masih berbentuk continue, sehingga perlu diskritkan terlebih dahulu semua variabel X-nya. Pada kasus ini data yang sama atau melebihi nilai rata-ratanya akan di kodekan 1 dan sebaliknya akan dikodekan 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [0, 0, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 0, 1, 1],\n",
       "       [0, 0, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 0, 1, 0],\n",
       "       [1, 0, 1, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 1, 1],\n",
       "       [0, 0, 1, 0],\n",
       "       [1, 0, 1, 1],\n",
       "       [0, 0, 1, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [0, 0, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [0, 0, 1, 1],\n",
       "       [0, 0, 1, 1],\n",
       "       [0, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [0, 0, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 1, 1],\n",
       "       [0, 0, 1, 1],\n",
       "       [0, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [0, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [0, 0, 1, 1],\n",
       "       [0, 0, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 0, 1, 1]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribute_mean = X.mean(axis=0)\n",
    "X_d = np.array(X >= attribute_mean, dtype='int') # transfer continuous value to discrete discretization of continuous values\n",
    "X_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fungsi ini berfungsi untuk menghitung most frequent class dan errornya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_feature_value(X, y_true, feature_index, value):\n",
    "    # create a dictionary to count how frequenctly a sample given a specific feature appears in certian class\n",
    "    #Create a dictionary to count the frequency of occurrence of a feature in a category\n",
    "    class_counts = defaultdict(int)\n",
    "    for sample, y in zip(X,y_true):\n",
    "        if sample[feature_index] == value:\n",
    "            class_counts[y] += 1\n",
    "            \n",
    "    # get the best one by sorting The category in which the feature value is most likely to belong\n",
    "    sorted_class_counts = sorted(class_counts.items(), key=itemgetter(1), reverse=True)\n",
    "    most_frequent_class = sorted_class_counts[0][0]\n",
    "    \n",
    "    #error is the number of samples that do not classified as the most frequent class 1- eigenvalues ​​belonging to most_frequent_class\n",
    "    incorrect_predictions = [class_count for class_value, class_count in class_counts.items() if class_value != most_frequent_class]\n",
    "    error = sum(incorrect_predictions)\n",
    "    return most_frequent_class, error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fungsi ini berfungsi untuk mengitung total error setiap predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_value(X, y_true, feature_index):\n",
    "    predictors = {} #create a dictionary with key denoting feature value and value denoting which class it belongs\n",
    "    errors = []\n",
    "    values = set(X[:, feature_index])\n",
    "    for v in values:\n",
    "        most_frequent_class, error = train_feature_value(X, y_true, feature_index, v)\n",
    "        predictors[v] = most_frequent_class\n",
    "        errors.append(error)\n",
    "\n",
    "    total_error = sum(errors)\n",
    "    return predictors, total_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah Training Data :  112  | Jumlah Test Data :  38\n"
     ]
    }
   ],
   "source": [
    "Xd_train, Xd_test, y_train, y_test = train_test_split(X_d, y, random_state=14)\n",
    "print(\"Jumlah Training Data : \", len(Xd_train), \" | Jumlah Test Data : \", len(Xd_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature': 2, 'predictor': {0: 0, 1: 2}}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictors = {}\n",
    "errors = {}\n",
    "for feature_index in range(Xd_train.shape[1]):\n",
    "    predictor, error = train_on_value(Xd_train, y_train, feature_index)\n",
    "    all_predictors[feature_index] = predictor\n",
    "    errors[feature_index] = error\n",
    "    \n",
    "#established classification prediction model   \n",
    "best_feature, best_error = sorted(errors.items(), key=itemgetter(1))[0]\n",
    "model = {\"feature\": best_feature, 'predictor': all_predictors[best_feature]}\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {0: 0, 1: 2}, 1: {0: 1, 1: 0}, 2: {0: 0, 1: 2}, 3: {0: 0, 1: 2}}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fungsi ini digunakan untuk memprediksi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test, model):\n",
    "    feature = model[\"feature\"]\n",
    "    predictor = model[\"predictor\"]\n",
    "    y_predicted = np.array([predictor[int(sample[feature])] for sample in X_test])\n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'setosa', 'setosa', 'virginica', 'virginica',\n",
       "       'virginica', 'setosa', 'virginica', 'setosa', 'virginica',\n",
       "       'virginica', 'setosa', 'virginica', 'virginica', 'setosa',\n",
       "       'virginica', 'setosa', 'virginica', 'virginica', 'virginica',\n",
       "       'setosa', 'setosa', 'setosa', 'virginica', 'setosa', 'virginica',\n",
       "       'setosa', 'virginica', 'virginica', 'setosa', 'setosa', 'setosa',\n",
       "       'virginica', 'setosa', 'virginica', 'setosa', 'virginica',\n",
       "       'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = predict(Xd_test, model)\n",
    "dataset.target_names[y_predicted]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.6578947368421053\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean(y_predicted == y_test)\n",
    "print(\"Accuracy : {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Prediction New Data\n",
    "Misalnya kita memiliki bunga dengan sepal_length = 0.4, sepal_width = 1, petal_length = 2.3, dan petal_width = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'setosa'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = pd.DataFrame(np.array([[0.4,1,2.3,2.5]]))\n",
    "# Konversi data ke kategorik\n",
    "new_data_d = np.array(new_data >= np.array(attribute_mean), dtype=\"int\")\n",
    "predicted = predict(new_data_d, model)\n",
    "dataset.target_names[predicted][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
